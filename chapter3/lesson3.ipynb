{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ed165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb15f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dotenv module\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea423176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "client = TavilySearch(max_results=5, include_answer=True)\n",
    "result = client.invoke({'query':\"What is in Nvidia's new Blackwell GPU?\"})\n",
    "\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"San Francisco\"\n",
    "\n",
    "query = f\"\"\"\n",
    "    what is the current weather in {city}?\n",
    "    Should I travel there today?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de236f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from ddgs import DDGS\n",
    "import re\n",
    "\n",
    "def search(query, max_results=6):\n",
    "    try:\n",
    "        results = DDGS().text(query, max_results=max_results)\n",
    "        return [i[\"href\"] for i in results]\n",
    "    except Exception as e:\n",
    "        print(f\"returning previous results due to exception reaching ddg.\")\n",
    "        results = [ # cover case where DDG rate limits due to high deeplearning.ai volume\n",
    "            \"https://weather.com/weather/today/l/USCA0987:1:US\",\n",
    "            \"https://weather.com/weather/hourbyhour/l/54f9d8baac32496f6b5497b4bf7a277c3e2e6cc5625de69680e6169e7e38e9a8\",\n",
    "        ]\n",
    "        return results  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a84a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_weather_info(url):\n",
    "    \"\"\"Scrape content from the given URL\"\"\"\n",
    "    if not url:\n",
    "        return \"Weather information could not be found.\"\n",
    "    \n",
    "    # fetch data\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return \"Failed to retrieve the webpage.\"\n",
    "    \n",
    "    # parse result\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DuckDuckGo to find websites and take the first result\n",
    "url = search(query)[0]\n",
    "\n",
    "# scrape the first website\n",
    "soup = scrape_weather_info(url)\n",
    "\n",
    "print(f\"Website: {url}\\n\\n\")\n",
    "print(str(soup.body)[:50000]) # limit long outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06df920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text\n",
    "weather_data = []\n",
    "for tag in soup.find_all(['h1', 'h2', 'h3', 'p']):\n",
    "    text = tag.get_text(\" \", strip=True)\n",
    "    weather_data.append(text)\n",
    "\n",
    "# combine all elements into a single string\n",
    "weather_data = \"\\n\".join(weather_data)\n",
    "\n",
    "# remove all spaces from the combined text\n",
    "weather_data = re.sub(r'\\s+', ' ', weather_data)\n",
    "print(f\"Website: {url}\\n\\n\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run search\n",
    "result = client.invoke(query, max_results=1)\n",
    "\n",
    "# print first result\n",
    "data = result[\"results\"][0][\"content\"]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "\n",
    "# parse JSON\n",
    "parsed_json = json.loads(data.replace(\"'\", '\"'))\n",
    "\n",
    "# pretty print JSON with syntax highlighting\n",
    "formatted_json = json.dumps(parsed_json, indent=4)\n",
    "colorful_json = highlight(formatted_json,\n",
    "                          lexers.JsonLexer(),\n",
    "                          formatters.TerminalFormatter())\n",
    "\n",
    "print(colorful_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
